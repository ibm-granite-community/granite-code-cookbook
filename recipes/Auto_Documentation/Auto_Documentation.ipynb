{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6rko_ANX0EC"
   },
   "source": [
    "# Auto-generating Documentation: A Long Document Summarization Approach\n",
    "\n",
    "This notebook demonstrates an innovative application of long document summarization techniques to automatically generate documentation for Python code. By treating a codebase as a \"long document,\" we leverage AI-powered language models to comprehend, distill, and explain complex code structures.\n",
    "\n",
    "Key concepts:\n",
    "1. Document preprocessing: We fetch and format code from a GitHub repository, similar to how one might prepare a long text document for summarization.\n",
    "2. Chunking and tokenization: We analyze the token count of our code \"document\" to ensure it fits within the model's context window, a crucial step in long document processing.\n",
    "3. Prompt engineering: We craft a specialized prompt that guides the AI to focus on key aspects of the code, much like how summarization prompts direct models to capture essential information.\n",
    "4. AI-powered analysis: Using the Replicate API, we access a large language model capable of understanding code semantics and generating human-readable explanations.\n",
    "5. Structured output: We instruct the model to produce documentation in a consistent format, analogous to generating structured summaries from lengthy texts.\n",
    "\n",
    "This approach demonstrates how techniques traditionally used for summarizing long articles, reports, or books can be adapted for technical documentation tasks. It showcases the versatility of large language models in processing and synthesizing complex information, whether it's natural language or programming code.\n",
    "\n",
    "By the end of this notebook, you'll see how principles of long document summarization can be applied to streamline and enhance the software documentation process, potentially saving developers significant time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwS1CzAbaFzq"
   },
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Before we begin, we need to install the required Python packages. We'll be using:\n",
    "\n",
    "- `replicate`: To interact with the Replicate API for accessing AI models\n",
    "- `transformers`: For tokenization and working with language models\n",
    "\n",
    "These packages will be installed using pip, Python's package installer. If you're running this notebook in a fresh environment, make sure you have pip installed and updated (if you are in Colab, this is done for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2zUHQD71qgqf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ibm-granite-community/utils.git\n",
      "  Cloning https://github.com/ibm-granite-community/utils.git to /private/var/folders/8t/m9m188_d0tb8szvfqlc20hfr0000gn/T/pip-req-build-mxkj_zhg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils.git /private/var/folders/8t/m9m188_d0tb8szvfqlc20hfr0000gn/T/pip-req-build-mxkj_zhg\n",
      "  Resolved https://github.com/ibm-granite-community/utils.git to commit a5965f40db3950dd2a41f3ca62a2c34adcdc20d7\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: replicate in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (1.0.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: python-dotenv in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from ibm-granite-community-utils==0.1.dev46) (1.0.1)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from replicate) (24.2)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from replicate) (2.10.4)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from replicate) (4.12.2)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: anyio in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (4.7.0)\n",
      "Requirement already satisfied: certifi in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.24.0->transformers)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from pydantic>1.10.7->replicate) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.0 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/utils.git replicate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydrVWz7EYHh9"
   },
   "source": [
    "## Set Replicate Token\n",
    "\n",
    "To use the Replicate API, we need to authenticate our requests. This is done using an API token.\n",
    "\n",
    "For security reasons, it's best to store this token as an environment variable rather than hardcoding it into our script. If we are using Google Colab, the `get_env_var` function will use the `userdata` feature to retrieve the token\n",
    "and set it in the environment variable.\n",
    "\n",
    "Remember to never share your API tokens publicly or commit them to version control systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TSkiGBY4qo32"
   },
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "get_env_var(\"REPLICATE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d0sWaZ7YLHN"
   },
   "source": [
    "## Define a function for downloading a repository\n",
    "\n",
    "We'll create a function to fetch code from a GitHub repository. This allows us to easily obtain the code we want to document.\n",
    "\n",
    "Key points about this function:\n",
    "- It uses the GitHub API to retrieve repository contents\n",
    "- It can handle both files and directories recursively\n",
    "- The function formats the code with appropriate language tags for better display\n",
    "- An optional GitHub token can be provided for increased API rate limits and access to private repositories\n",
    "\n",
    "Note on GitHub tokens:\n",
    "A GitHub token is not required for public repositories, but it can be beneficial. With a token, you can:\n",
    "1. Access private repositories\n",
    "2. Have a higher rate limit for API requests\n",
    "3. Fetch more detailed information about the repository\n",
    "\n",
    "To create a GitHub token, go to your GitHub account settings, select \"Developer settings\", then \"Personal access tokens\".  Find more information [here](https://docs.github.com/en/rest/authentication/authenticating-to-the-rest-api?apiVersion=2022-11-28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3JFi40LArpIa"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_github_repo_contents(repo, directory_path, github_token = None):\n",
    "\n",
    "    api_url = f\"https://api.github.com/repos/{repo}/contents/{directory_path}\"\n",
    "    if github_token is not None:\n",
    "      headers = {'Authorization': f'token {github_token}'}\n",
    "      response = requests.get(api_url, headers = headers)\n",
    "    else:\n",
    "      response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    contents = response.json()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for item in contents:\n",
    "        if item['type'] == 'file':\n",
    "            file_response = requests.get(item['download_url'])\n",
    "            file_response.raise_for_status()\n",
    "            file_content = file_response.text\n",
    "            language = item['name'].split('.')[-1]\n",
    "            if language == 'py':\n",
    "                language = 'python'\n",
    "            elif language == 'js':\n",
    "                language = 'javascript'\n",
    "            result.append(f\"{item['path']}\\n```{language}\\n{file_content}\\n```\")\n",
    "        elif item['type'] == 'dir':\n",
    "            # Recursively go through subdirectories\n",
    "            subdirectory_contents = get_github_repo_contents(repo, item['path'], github_token)\n",
    "            result.append(subdirectory_contents)\n",
    "        sleep(0.1)\n",
    "\n",
    "    return \"\\n\\n\".join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-06VQn1YmtU"
   },
   "source": [
    "## Get code from `ibm-granite-community/utils`\n",
    "\n",
    "In this example, we're focusing on the `ibm-granite-community/utils` repository, specifically the `src` directory. This directory contains various utility functions that we want to document.\n",
    "\n",
    "By specifying this directory, we ensure that we're only fetching the relevant code and not unnecessary files or directories. This helps to keep our input focused and reduces the likelihood of exceeding token limits in our AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k2wS6rGJsu-T"
   },
   "outputs": [],
   "source": [
    "prompt = get_github_repo_contents(\"ibm-granite-community/utils\", \"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYuQmgRJY0n5"
   },
   "source": [
    "## Count the tokens\n",
    "\n",
    "Before sending our code to the AI model, it's crucial to understand how much of the model's capacity we're using. Language models typically have a limit on the number of tokens they can process in a single request.\n",
    "\n",
    "Key points:\n",
    "- We're using the `granite-8B-Code-instruct-128k` model, which has a context window of 128,000 tokens\n",
    "- The context window includes both the input (our code) and the output (the generated documentation)\n",
    "- Tokenization can vary between models, so we use the specific tokenizer for our chosen model\n",
    "- If our input is too large, we may need to split it into smaller chunks or summarize it\n",
    "\n",
    "Understanding token count helps us optimize our prompts and ensure we're using the model efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7JqmvTqbWPgl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravinkedia/Downloads/LatestCookBook/granite-code-cookbook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your git repo load has 673 tokens\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.1-8b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "print(f\"Your git repo load has {len(tokenizer.tokenize(prompt))} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygNmITWQZAZ8"
   },
   "source": [
    "### Create our prompt and call the model in Replicate\n",
    "\n",
    "This is where we construct our final prompt and send it to the AI model for processing.\n",
    "\n",
    "Our approach involves:\n",
    "1. Combining the code we fetched with specific instructions for documentation\n",
    "2. Using a template to guide the model's output format\n",
    "3. Calling the Replicate API with our constructed prompt and additional parameters\n",
    "\n",
    "Key considerations:\n",
    "- The prompt includes both the code and instructions for how to document it\n",
    "- We use a response template to ensure consistent formatting across functions\n",
    "- Parameters like `max_tokens`, `temperature`, and `system_prompt` can be adjusted to fine-tune the model's behavior\n",
    "- The output is streamed, allowing for real-time display of the generated documentation\n",
    "\n",
    "This step is where the magic happens - transforming our code into human-readable documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yu4HeuqWqvOj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## `is_colab()`\n",
      "\n",
      "* `_return_`: (bool) Returns `True` if the code is running in Google Colab, `False` otherwise.\n",
      "\n",
      "This function checks if the code is running in Google Colab by using the `importlib.util.find_spec` function to check if the `google.colab` module is available.\n",
      "\n",
      "**returns**:\n",
      "\n",
      "\n",
      "- `True` if the code is running in Google Colab, `False` otherwise.\n",
      "\n",
      "## `get_env_var(var_name, default_value)`\n",
      "\n",
      "* `_param1_`: (str) The name of the environment variable to retrieve.\n",
      "* `_param2_`: (str | None, optional) The default value to return if the environment variable is not found. Default is `None`.\n",
      "* `_return_`: (str | None) The value of the environment variable if found, or the default value if not found.\n",
      "\n",
      "This function retrieves the value of an environment variable by checking the `os.environ` dictionary for the specified variable name. If the variable is not found, it checks if the code is running in Google Colab and, if so, attempts to retrieve the value from a secret using the `google.colab.userdata` module. If the variable is still not found, it attempts to load the API key from a `.env` file using the `python-dotenv` module. If the variable is still not found and a default value is provided, it uses the default value. If the variable is still not found and no default value is provided, it prompts the user to enter the value.\n",
      "\n",
      "**returns**:\n",
      "\n",
      "\n",
      "- The value of the environment variable if found, or the default value if not found.\n",
      "\n",
      "## `set_env_var(var_name, default_value)`\n",
      "\n",
      "* `_param1_`: (str) The name of the environment variable to set.\n",
      "* `_param2_`: (str | None, optional) The default value to use if the environment variable is not found. Default is `None`.\n",
      "* `_return_`: (None)\n",
      "\n",
      "This function sets the value of an environment variable by first checking if it already exists in `os.environ`. If not, it calls the `get_env_var` function to retrieve the value of the environment variable. If the value is not found, it uses the default value if provided. If no default value is provided, it prompts the user to enter the value.\n",
      "\n",
      "**returns**:\n",
      "\n",
      "\n",
      "- `None`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "full_prompt = prompt + \"\"\"\n",
    "\n",
    "Provide detailed developer documentation for each function provided above.\n",
    "\n",
    "Response Template:\n",
    "## `function_name`\n",
    "\n",
    "* _param1_: (type) description\"\n",
    "\n",
    "Synopsis of the function\n",
    "\n",
    "_**returns**_:\n",
    "\"\"\"\n",
    "\n",
    "output = replicate.run(\n",
    "    \"ibm-granite/granite-8b-code-instruct-128k\",\n",
    "    input={\n",
    "\n",
    "        \"prompt\": full_prompt,\n",
    "        \"max_tokens\": 10000,\n",
    "        \"min_tokens\": 0,\n",
    "        \"temperature\": 0.75,\n",
    "        \"system_prompt\": \"You are a helpful assistant.\",\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"\".join(output))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

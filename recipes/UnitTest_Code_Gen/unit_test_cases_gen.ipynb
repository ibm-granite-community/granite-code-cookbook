{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e98b2a4-cf47-4523-bd07-827683728d31",
   "metadata": {},
   "source": [
    "# Use Remote Granite Code Models (20B) with LangChain for Unit Test Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45854-f221-466b-a0b4-78effeae9f41",
   "metadata": {},
   "source": [
    "## Introduction and Setup\n",
    " \n",
    "This notebook demonstrates how to generate unit tests for Python functions and classes using inference calls against a model hosted remotely on [Replicate](https://replicate.com/). The use case targets developers who are looking to streamline the process of creating unit tests with minimal manual effort. The system takes Python code as input and returns unit test code, incorporating \"test doubles\" for external dependencies.  The notebook depends on Granite [`Utils`](https://github.com/ibm-granite-community/utils) package for integration with LLMs using Langchain framework.\n",
    " \n",
    " \n",
    "#### Pre-requisites\n",
    "\n",
    "To run this notebook, ensure you have the following:\n",
    "\n",
    "1. Python version: 3.9 or higher\n",
    "2. langchain_community<0.3.0\n",
    "3. langchain_ollama<0.2.0\n",
    "4. replicate\n",
    "\n",
    "#### Model Details:\n",
    "\n",
    "1. Model Platform : Replicate\n",
    "2. Model : IBM Granite 20b Code Instruct 8k\n",
    "3. Model Version : ibm-granite/granite-20b-code-instruct-8k:409a0c68b74df416c7ae2a3f1552101123356f5a2c6e46d681629b62904c605b\n",
    "\n",
    "#### Program \n",
    "1. Input : Python code/snippets with instructions for test packages that need to utilized and optional type of unit test case scenarios to be covered\n",
    "2. Output : Python code with unit test packages and libraries, test doubles , assert implementation for Unit testing of given input \n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "Results of 20b code instruct granite model using 8k context appears convincing than 8b code instruct granite model with 128k context. The code generated may need additional modification dependending on the libraries and user input \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8537f",
   "metadata": {},
   "source": [
    "### Install required Langchain replicate packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  langchain_community replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b04485-3c77-40c3-a4ba-0a901f747f42",
   "metadata": {},
   "source": [
    "### Install Granite `utils` package\n",
    "\n",
    "This package is a thin shim with various functions that are required for notebooks.\n",
    "\n",
    "To see the implementation of its functions, see the [utils repo](https://github.com/ibm-granite-community/utils/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119fc048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ibm-granite-community/utils\n",
      "  Cloning https://github.com/ibm-granite-community/utils to c:\\users\\012721744\\appdata\\local\\temp\\pip-req-build-qf9bp88y\n",
      "  Resolved https://github.com/ibm-granite-community/utils to commit bc18a5c8b8f3d645032ec765f9d3415e359c87e0\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from ibm_granite_community==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: langchain-community<0.3.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from ibm_granite_community==0.1.0) (0.2.17)\n",
      "Requirement already satisfied: langchain-ollama<0.2.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from ibm_granite_community==0.1.0) (0.1.3)\n",
      "Requirement already satisfied: replicate in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from ibm_granite_community==0.1.0) (0.33.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.39 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.2.40)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.1.121)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-community<0.3.0->ibm_granite_community==0.1.0) (8.5.0)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-ollama<0.2.0->ibm_granite_community==0.1.0) (0.3.3)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from replicate->ibm_granite_community==0.1.0) (0.27.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from replicate->ibm_granite_community==0.1.0) (24.1)\n",
      "Requirement already satisfied: pydantic>1.10.7 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from replicate->ibm_granite_community==0.1.0) (2.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from replicate->ibm_granite_community==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.11.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate->ibm_granite_community==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain-community<0.3.0->ibm_granite_community==0.1.0) (0.2.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.39->langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from pydantic>1.10.7->replicate->ibm_granite_community==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from pydantic>1.10.7->replicate->ibm_granite_community==0.1.0) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0->ibm_granite_community==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.39->langchain-community<0.3.0->ibm_granite_community==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\012721744\\desktop\\sree\\ai\\tel\\cookbook\\recipes\\unittestcasesfinal\\testutil\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0->ibm_granite_community==0.1.0) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils 'C:\\Users\\012721744\\AppData\\Local\\Temp\\pip-req-build-qf9bp88y'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install git+https://github.com/ibm-granite-community/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f173a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.langchain_utils import find_langchain_model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2db6c-f3cc-48a1-94c8-d12849446a77",
   "metadata": {},
   "source": [
    "### Define a Prompt\n",
    "\n",
    "The cells below demonstrate a remote option and a local option for model inference.\n",
    "\n",
    "Both will perform a blocking call using the following system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f99de7-ff2e-4ae4-b1f2-1ac4453b4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =   \"\"\"Role: Python Code Generator.\n",
    "           User Input: <Python code>, optional Test libraries, output file locations ..\n",
    "           Output: Python code for unit testing success and failure conditions of the given input <python code> leveraging the test libraries \n",
    "           Validity: Generates error-free unit test code for the input <python code> by importing those libraries\n",
    "           Test Libraries: User provided test libraries.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1f48d-a625-4210-80ef-a505c728b331",
   "metadata": {},
   "source": [
    "## Remote Model using Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386acab-a8c6-41cc-b9b8-e20494ca4828",
   "metadata": {},
   "source": [
    "### Establish Replicate Account\n",
    "\n",
    "To use this remote option, create an account at [Replicate](https://replicate.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad8255",
   "metadata": {},
   "source": [
    "### Provide your API token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f99fa",
   "metadata": {},
   "source": [
    "\n",
    "Obtain your REPLICATE_API_TOKEN at replicate.com/account/api-tokens\n",
    "\n",
    "There are three ways to provide this value to the cells below. In order of precedence:\n",
    "\n",
    "1. As an environment variable\n",
    "2. As a Google colab secret\n",
    "3. Supplied by the user using getpass()\n",
    "\n",
    "Here: Created a  environment variable `REPLICATE_API_TOKEN='xxxxx'` in `.env` file in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3e69f-82cb-424d-8358-d981453aab93",
   "metadata": {},
   "source": [
    "### Choose a Model\n",
    "\n",
    "Two Granite Code models are available in the [`ibm-granite`](https://replicate.com/ibm-granite) org at Replicate.\n",
    "\n",
    "The `find_langchain_model` function below imports the `replicate` package.\n",
    "\n",
    "Model Arguments are defined using input parameters dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1569c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"ibm-granite/granite-8b-code-instruct-128k\"\n",
    "\n",
    "model_id=\"ibm-granite/granite-20b-code-instruct-8k\"\n",
    " \n",
    "input_parameters = {      \n",
    "        \"top_k\": 60,\n",
    "        \"top_p\": 0.3, \n",
    "        \"max_tokens\": 1000,\n",
    "        \"min_tokens\": 0,\n",
    "        \"temperature\": 0.3, \n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"system_prompt\": prompt\n",
    "        }\n",
    "granite_via_replicate = find_langchain_model(platform=\"replicate\", model_id=model_id,\n",
    "                                              model_kwargs=input_parameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcc704-3cab-4da5-8ada-9032d5bafdb4",
   "metadata": {},
   "source": [
    "### Perform Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf998562",
   "metadata": {},
   "source": [
    "#### Below use case covers generation of unit test code for the input code leveraging pytest library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a5b2e1-f7eb-4de3-bfb9-f049b0c3fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: Here is an example of how you can use pytest to generate unit test cases for the given code:\n",
      "\n",
      "import pytest\n",
      "from database import Database\n",
      "\n",
      "@pytest.fixture\n",
      "def db():\n",
      " # Initialize the database connection\n",
      " db = Database('example.db')\n",
      " \n",
      " # Connect to the database\n",
      " db.connect()\n",
      " \n",
      " yield db\n",
      " \n",
      " # Close the database connection\n",
      " db.close()\n",
      "\n",
      "def test_fetch_data(db):\n",
      " # Define a query to fetch data\n",
      " query = \"SELECT * FROM users\"  # Change this query according to your table structure\n",
      " \n",
      " # Fetch data\n",
      " data = db.fetch_data(query)\n",
      " \n",
      " # Assert that the fetched data is not empty\n",
      " assert data\n",
      " \n",
      " # Assert that the fetched data has the expected structure\n",
      " expected_structure = [(1, 'John', 'Doe'), (2, 'Jane', 'Smith')]  # Change this to match your table structure\n",
      " assert data == expected_structure\n",
      "\n",
      "def test_fetch_data_with_invalid_query(db):\n",
      " # Define an invalid query to fetch data\n",
      " query = \"SELECT * FROM nonexistent_table\"\n",
      " \n",
      " # Fetch data and assert that an exception is raised\n",
      " with pytest.raises(Exception):\n",
      " data = db.fetch_data(query)\n",
      "\n",
      "This is just an example, and you can modify the test cases to cover different scenarios and edge cases. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "codes=\"\"\"Use pytest test library to generate unit test cases for the below\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, db_name):\n",
    "        #Initialize with the database name.\n",
    "        self.db_name = db_name\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        #Establish a connection to the SQLite database.\n",
    "        self.conn = sqlite3.connect(self.db_name)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        print(\"Connected to the database.\")\n",
    "\n",
    "    def fetch_data(self, query):\n",
    "        #Fetch data from the database using the provided SQL query.\n",
    "        if not self.cursor:\n",
    "            raise RuntimeError(\"Database not connected.\")\n",
    "        self.cursor.execute(query)\n",
    "        return self.cursor.fetchall()\n",
    "\n",
    "    def close(self):\n",
    "        #Close the database connection.\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "def main():\n",
    "    # Initialize the database connection\n",
    "    db = Database('example.db')\n",
    "    \n",
    "    # Connect to the database\n",
    "    db.connect()\n",
    "    \n",
    "    # Define a query to fetch data\n",
    "    query = \"SELECT * FROM users\"  # Change this query according to your table structure\n",
    "    \n",
    "    # Fetch data\n",
    "    try:\n",
    "        data = db.fetch_data(query)\n",
    "        print(\"Fetched Data:\")\n",
    "        for row in data:\n",
    "            print(row)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "    finally:\n",
    "        # Close the database connection\n",
    "        db.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529170fc",
   "metadata": {},
   "source": [
    "#### Invoke the model to generate test cases for application code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799a386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: Here's an example of how you can generate unit test cases for the given function using the unittest library:\n",
      "\n",
      "import json\n",
      "import unittest\n",
      "from unittest.mock import patch\n",
      "\n",
      "def lambda_handler(event, context):\n",
      " if 'queryStringParameters' in event:    # If parameters\n",
      " print(event['queryStringParameters']['first_name'])\n",
      " print(event['queryStringParameters']['last_name'])\n",
      " body = 'Hello {} {}!'.format(event['queryStringParameters']['first_name'], \n",
      " event['queryStringParameters']['last_name'])  \n",
      " else:    # If no parameters\n",
      " print('No parameters!')\n",
      " body = 'Who are you?'\n",
      " \n",
      " return {\n",
      " 'statusCode': 200,\n",
      " 'body': json.dumps(body)\n",
      " }\n",
      "class LambdaHandlerTestCase(unittest.TestCase):\n",
      " @patch('__main__.print')\n",
      " def test_with_parameters(self, mock_print):\n",
      " event = {\n",
      " 'queryStringParameters': {\n",
      " 'first_name': 'John',\n",
      " 'last_name': 'Doe'\n",
      " }\n",
      " }\n",
      " result = lambda_handler(event, None)\n",
      " self.assertEqual(result['statusCode'], 200)\n",
      " self.assertEqual(result['body'], '\"Hello John Doe!\"')\n",
      " mock_print.assert_has_calls([\n",
      " ('John',),\n",
      " ('Doe',),\n",
      " ('Hello John Doe!',)\n",
      " ])\n",
      " \n",
      " @patch('__main__.print')\n",
      " def test_no_parameters(self, mock_print):\n",
      " event = {}\n",
      " result = lambda_handler(event, None)\n",
      " self.assertEqual(result['statusCode'], 200)\n",
      " self.assertEqual(result['body'], '\"Who are you?\"')\n",
      " mock_print.assert_called_once_with('No parameters!')\n",
      "if __name__ == '__main__':\n",
      " unittest.main()\n",
      "\n",
      "In this example, we use the unittest.TestCase class to create a test class for the lambda_handler function. We also use the patch decorator from the unittest.mock module to mock the print function that is called within the lambda_handler function.\n",
      "\n",
      "We then define two test methods, test_with_parameters and test_no_parameters, that simulate events with and without query string parameters, respectively. In each test method, we call the lambda_handler function with the appropriate event and assert that the returned result matches our expected output.\n",
      "\n",
      "Finally, we call unittest\n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\" Use unittest library to generate the unit test cases for the below\n",
    "import json\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    if 'queryStringParameters' in event:    # If parameters\n",
    "        print(event['queryStringParameters']['first_name'])\n",
    "        print(event['queryStringParameters']['last_name'])\n",
    "        body = 'Hello {} {}!'.format(event['queryStringParameters']['first_name'], \n",
    "                                    event['queryStringParameters']['last_name'])  \n",
    "    else:    # If no parameters\n",
    "        print('No parameters!')\n",
    "        body = 'Who are you?'\n",
    "        \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(body)\n",
    "    }\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9ab73",
   "metadata": {},
   "source": [
    "#### Here is another example how user can provide multiple functions code as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f89013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: To perform unit testing on the given functions, we can use a unit testing framework such as unittest in Python. Here is an example of how we can write unit tests for the given functions:\n",
      "\n",
      "import unittest\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "\n",
      "class TestFunctions(unittest.TestCase):\n",
      " def test_load_data(self):\n",
      " points = np.loadtxt('data.csv', delimiter=',') \n",
      " y_ = points[:,1]\n",
      " # append '1' to account for the intercept\n",
      " x_ = np.ones([len(y_),2]) \n",
      " x_[:,0] = points[:,0]\n",
      " # display plot\n",
      " #plt.plot(x_[:,0], y_, 'ro')\n",
      " #plt.xlabel('x-axis')\n",
      " #plt.ylabel('y-axis')\n",
      " #plt.show()\n",
      " self.assertEqual(x_.shape, (10000, 2))\n",
      " self.assertEqual(y_.shape, (10000,))\n",
      " def test_evaluate_cost(self):\n",
      " x_ = np.array([[1, 2], [3, 4], [5, 6]])\n",
      " y_ = np.array([1, 2, 3])\n",
      " params = np.array([0.5, 0.5])\n",
      " cost = evaluate_cost(x_, y_, params)\n",
      " self.assertEqual(cost, 0.5)\n",
      " def test_evaluate_gradient(self):\n",
      " x_ = np.array([[1, 2], [3, 4], [5, 6]])\n",
      " y_ = np.array([1, 2, 3])\n",
      " params = np.array([0.5, 0.5])\n",
      " gradient = evaluate_gradient(x_, y_, params)\n",
      " self.assertEqual(gradient, [0.5, 0.5])\n",
      "\n",
      "if __name__ == '__main__':\n",
      " unittest.main()\n",
      "\n",
      "In this example, we have created a test class TestFunctions that inherits from unittest.TestCase. Inside this class, we have defined three test methods test_load_data, test_evaluate_cost, and test_evaluate_gradient.\n",
      "Each test method starts with the word \"test\" and contains a series of assertions that check the output of the corresponding function against the expected output. For example, in the test_load_data\n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\"Here are the function definitions to be unit tested\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def load_data(fname):\n",
    "    points = np.loadtxt(fname, delimiter=',') \n",
    "    y_ = points[:,1]\n",
    "    # append '1' to account for the intercept\n",
    "    x_ = np.ones([len(y_),2]) \n",
    "    x_[:,0] = points[:,0]\n",
    "    # display plot\n",
    "    #plt.plot(x_[:,0], y_, 'ro')\n",
    "    #plt.xlabel('x-axis')\n",
    "    #plt.ylabel('y-axis')\n",
    "    #plt.show()\n",
    "    print('data loaded. x:{} y:{}'.format(x_.shape, y_.shape))\n",
    "    return x_, y_\n",
    "\n",
    "def evaluate_cost(x_,y_,params):\n",
    "    tempcost = 0\n",
    "    for i in range(len(y_)):\n",
    "        tempcost += (y_[i] - ((params[0] * x_[i,0]) + params[1])) ** 2 \n",
    "    return tempcost / float(10000)   \n",
    "\n",
    "def evaluate_gradient(x_,y_,params):\n",
    "    m_gradient = 0\n",
    "    b_gradient = 0\n",
    "    N = float(len(y_))\n",
    "    for i in range(len(y_)):\n",
    "        m_gradient += -(2/N) * (x_[i,0] * (y_[i] - ((params[0] * x_[i,0]) + params[1])))\n",
    "        b_gradient += -(2/N) * (y_[i] - ((params[0] * x_[i,0]) + params[1]))\n",
    "    return [m_gradient,b_gradient]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275593b1",
   "metadata": {},
   "source": [
    "#### Example for user input leveraging middleware code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001fe1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: Here is a sample unit test code using pytest library package for the given code:\n",
      "```\n",
      "import pytest\n",
      "from pyspark.sql import SparkSession\n",
      "from pyspark.sql.functions import from_json, to_json, struct, to_timestamp, from_unixtime\n",
      "from sentiment import Sentiment\n",
      "topic_name = \"twitter_topic\"\n",
      "output_topic = \"output_topic\"\n",
      "@pytest.fixture(scope=\"module\")\n",
      "def spark_session():\n",
      " # create Spark session\n",
      " spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
      " spark.sparkContext.setLogLevel(\"ERROR\") # Ignore INFO DEBUG output\n",
      " return spark\n",
      "def test_df_type(spark_session):\n",
      " df = spark_session         .readStream         .format(\"kafka\")         .option(\"kafka.bootstrap.servers\", \"localhost:9092\")         .option(\"subscribe\", topic_name)         .load()\n",
      " \n",
      " df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
      " \n",
      " df = df.withColumn(\"data\", from_json(df.value, Sentiment.get_schema())).select(\"data.*\")\n",
      " df = df         .withColumn(\"ts\", to_timestamp(from_unixtime(expr(\"timestamp_ms/1000\"))))         .withWatermark(\"ts\", \"1 seconds\") # old data will be removed\n",
      " \n",
      " # Preprocess the data\n",
      " df = Sentiment.preprocessing(df)\n",
      " \n",
      " # text classification to define polarity and subjectivity\n",
      " df = Sentiment.text_classification(df)\n",
      " \n",
      " assert type(df) == pyspark.sql.dataframe.DataFrame\n",
      " \n",
      " row_df = df.select(\n",
      " to_json(struct(\"id\")).alias('key'),\n",
      " to_json(struct('text', 'lang', 'ts', 'polarity_v', 'polarity', 'subjectivity_v')).alias(\"value\")\n",
      " )\n",
      " \n",
      " assert type(row_df) == pyspark.sql.dataframe.DataFrame\n",
      " \n",
      " row_df = row_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
      " \n",
      " return row_df\n",
      "def test_write_to_kafka(row_df):\n",
      " query = row_df         .writeStream         .format(\"kafka\")         .option(\"kafka.bootstrap.servers\", \"localhost:9092\")         .option\n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\" For the below code write unit test code using pytest library package\n",
    "if __name__ == \"__main__\":\n",
    "    # create Spark session\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\") # Ignore INFO DEBUG output\n",
    "    df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "        .option(\"subscribe\", topic_name) \\\n",
    "        .load()\n",
    "\n",
    "    df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "    df = df.withColumn(\"data\", from_json(df.value, Sentiment.get_schema())).select(\"data.*\")\n",
    "    df = df \\\n",
    "        .withColumn(\"ts\", to_timestamp(from_unixtime(expr(\"timestamp_ms/1000\")))) \\\n",
    "        .withWatermark(\"ts\", \"1 seconds\") # old data will be removed\n",
    "\n",
    "    # Preprocess the data\n",
    "    df = Sentiment.preprocessing(df)\n",
    "\n",
    "    # text classification to define polarity and subjectivity\n",
    "    df = Sentiment.text_classification(df)\n",
    "\n",
    "    assert type(df) == pyspark.sql.dataframe.DataFrame\n",
    "\n",
    "    row_df = df.select(\n",
    "        to_json(struct(\"id\")).alias('key'),\n",
    "        to_json(struct('text', 'lang', 'ts', 'polarity_v', 'polarity', 'subjectivity_v')).alias(\"value\")\n",
    "    )\n",
    " \n",
    "\n",
    "    # Writing to Kafka\n",
    "    query = row_df\\\n",
    "        .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "        .writeStream\\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "        .option(\"topic\", output_topic) \\\n",
    "        .option(\"checkpointLocation\", \"file:/Users/user/tmp\") \\\n",
    "        .start()\n",
    " \n",
    "    query.awaitTermination()\"\"\"\n",
    "\n",
    " \n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c4e5f",
   "metadata": {},
   "source": [
    "#### Here is a scenario with user input code as class definition to generate test cases code using test doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07f2080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: To test the `Sentiment` class using pytest and fixtures, you can create a test module with the following code:\n",
      "```python\n",
      "import pytest\n",
      "from pyspark.sql.types import *\n",
      "from pyspark.sql.functions import col, explode, split, udf, when\n",
      "from textblob import TextBlob\n",
      "from sentiment import Sentiment\n",
      "\n",
      "@pytest.fixture\n",
      "def sentiment():\n",
      " return Sentiment()\n",
      "\n",
      "def test_get_schema(sentiment):\n",
      " schema = sentiment.get_schema()\n",
      " assert isinstance(schema, StructType)\n",
      " assert len(schema.fields) == 23\n",
      "\n",
      "def test_preprocessing(sentiment):\n",
      " df = spark.createDataFrame([(\"test\",)], [\"text\"])\n",
      " df = sentiment.preprocessing(df)\n",
      " assert df.count() == 1\n",
      " assert df.first().text == \"test\"\n",
      "\n",
      "def test_polarity_detection(sentiment):\n",
      " assert sentiment.polarity_detection(\"test\") == 0.0\n",
      "\n",
      "def test_subjectivity_detection(sentiment):\n",
      " assert sentiment.subjectivity_detection(\"test\") == 0.0\n",
      "\n",
      "def test_text_classification(sentiment):\n",
      " words = spark.createDataFrame([(\"test\",)], [\"text\"])\n",
      " words = sentiment.text_classification(words)\n",
      " assert words.count() == 1\n",
      " assert words.first().polarity == \"Neutral\"\n",
      " assert words.first().subjectivity == \"Neutral\"\n",
      "```\n",
      "In this example, we create a fixture `sentiment` that creates an instance of the `Sentiment` class. We then use this fixture in the test functions to create test data and assert the expected results. \n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\"Below is the class definition to be tested using pytest library and fixtures. Use below class instances for unit test modules\n",
    "\n",
    "class Sentiment:\n",
    "    def get_schema():\n",
    "        schema = StructType([\n",
    "            StructField(\"created_at\", StringType()),\n",
    "            StructField(\"id\", StringType()),\n",
    "            StructField(\"text\", StringType()),\n",
    "            StructField(\"source\", StringType()),\n",
    "            StructField(\"truncated\", StringType()),\n",
    "            StructField(\"in_reply_to_status_id\", StringType()),\n",
    "            StructField(\"in_reply_to_user_id\", StringType()),\n",
    "            StructField(\"in_reply_to_screen_name\", StringType()),\n",
    "            StructField(\"user\", StringType()),\n",
    "            StructField(\"coordinates\", StringType()),\n",
    "            StructField(\"place\", StringType()),\n",
    "            StructField(\"quoted_status_id\", StringType()),\n",
    "            StructField(\"is_quote_status\", StringType()),\n",
    "            StructField(\"quoted_status\", StringType()),\n",
    "            StructField(\"retweeted_status\", StringType()),\n",
    "            StructField(\"quote_count\", StringType()),\n",
    "            StructField(\"reply_count\", StringType()),\n",
    "            StructField(\"retweet_count\", StringType()),\n",
    "            StructField(\"favorite_count\", StringType()),\n",
    "            StructField(\"entities\", StringType()),\n",
    "            StructField(\"extended_entities\", StringType()),\n",
    "            StructField(\"favorited\", StringType()),\n",
    "            StructField(\"retweeted\", StringType()),\n",
    "            StructField(\"possibly_sensitive\", StringType()),\n",
    "            StructField(\"filter_level\", StringType()),\n",
    "            StructField(\"lang\", StringType()),\n",
    "            StructField(\"matching_rules\", StringType()),\n",
    "            StructField(\"name\", StringType()),\n",
    "            StructField(\"timestamp_ms\", StringType())\n",
    "        ])\n",
    "        return schema\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocessing(df):\n",
    "        # words = df.select(explode(split(df.text, \" \")).alias(\"word\"))\n",
    "        df = df.filter(col('text').isNotNull())\n",
    "        df = df.withColumn('text', regexp_replace('text', r'http\\S+', ''))\n",
    "        df = df.withColumn('text', regexp_replace('text', r'[^\\x00-\\x7F]+', ''))\n",
    "        df = df.withColumn('text', regexp_replace('text', r'[\\n\\r]', ' '))\n",
    "        df = df.withColumn('text', regexp_replace('text', '@\\w+', ''))\n",
    "        df = df.withColumn('text', regexp_replace('text', '#', ''))\n",
    "        df = df.withColumn('text', regexp_replace('text', 'RT', ''))\n",
    "        df = df.withColumn('text', regexp_replace('text', ':', ''))\n",
    "        df = df.withColumn('source', regexp_replace('source', '<a href=\"' , ''))\n",
    "\n",
    "        return df\n",
    "\n",
    "    # text classification\n",
    "    @staticmethod\n",
    "    def polarity_detection(text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    @staticmethod\n",
    "    def subjectivity_detection(text):\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "    @staticmethod\n",
    "    def text_classification(words):\n",
    "        # polarity detection\n",
    "        polarity_detection_udf = udf(Sentiment.polarity_detection, FloatType())\n",
    "        words = words.withColumn(\"polarity_v\", polarity_detection_udf(\"text\"))\n",
    "        words = words.withColumn(\n",
    "            'polarity',\n",
    "            when(col('polarity_v') > 0, lit('Positive'))\n",
    "            .when(col('polarity_v') == 0, lit('Neutral'))\n",
    "            .otherwise(lit('Negative'))\n",
    "        )\n",
    "        # subjectivity detection\n",
    "        subjectivity_detection_udf = udf(Sentiment.subjectivity_detection, FloatType())\n",
    "        words = words.withColumn(\"subjectivity_v\", subjectivity_detection_udf(\"text\"))\n",
    "        return words\n",
    "\n",
    "\"\"\"\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9597bd",
   "metadata": {},
   "source": [
    "#### Below example showcases code input with external api function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ea939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: Here is an example of unit testing code for the given code:\n",
      "\n",
      "import facebook\n",
      "import unittest\n",
      "from unittest.mock import patch, MagicMock\n",
      "\n",
      "class TestFacebookAPI(unittest.TestCase):\n",
      " @patch('facebook.GraphAPI')\n",
      " def test_get_friend_list(self, mock_graph):\n",
      " # Create a mock graph object with a predefined friend list\n",
      " mock_graph_instance = MagicMock()\n",
      " mock_graph_instance.get_object.return_value = {'name': 'John Doe'}\n",
      " mock_graph_instance.get_connections.return_value = {\n",
      " 'data': [\n",
      " {'name': 'Alice'},\n",
      " {'name': 'Bob'},\n",
      " {'name': 'Charlie'}\n",
      " ]\n",
      " }\n",
      " mock_graph.return_value = mock_graph_instance\n",
      " \n",
      " # Call the function being tested\n",
      " token = 'your token'\n",
      " graph = facebook.GraphAPI(token)\n",
      " profile = graph.get_object(\"me\")\n",
      " friends = graph.get_connections(\"me\", \"friends\")\n",
      " friend_list = [friend['name'] for friend in friends['data']]\n",
      " \n",
      " # Assert that the friend list is correct\n",
      " self.assertEqual(friend_list, ['Alice', 'Bob', 'Charlie'])\n",
      " \n",
      "if __name__ == '__main__':\n",
      " unittest.main()\n",
      "\n",
      "In this example, we use the patch decorator from the unittest.mock module to mock the GraphAPI class from the facebook module. We create a mock graph object with a predefined friend list and set it as the return value for the get_object and get_connections methods. We then call the function being tested (get_friend_list) and assert that the friend list returned by the function is correct. \n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\" Given the below code, provide unit testing code \n",
    "\n",
    "import facebook\n",
    "\n",
    "token = 'your token'\n",
    "\n",
    "graph = facebook.GraphAPI(token)\n",
    "profile = graph.get_object(\"me\")\n",
    "friends = graph.get_connections(\"me\", \"friends\")\n",
    "friend_list = [friend['name'] for friend in friends['data']]\n",
    "print friend_list\"\"\"\n",
    "\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769367c",
   "metadata": {},
   "source": [
    "#### Another example with external api function call code input but with explicit instruction to use pytest library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd30fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite response from Replicate: Here's an example of unit testing code using pytest for the given code:\n",
      "\n",
      "import pytest\n",
      "import facebook\n",
      "\n",
      "@pytest.fixture\n",
      "def token():\n",
      " return 'your token'\n",
      "\n",
      "def test_get_friend_list(token):\n",
      " graph = facebook.GraphAPI(token)\n",
      " profile = graph.get_object(\"me\")\n",
      " friends = graph.get_connections(\"me\", \"friends\")\n",
      " friend_list = [friend['name'] for friend in friends['data']]\n",
      " assert len(friend_list) > 0\n",
      " for friend in friend_list:\n",
      " assert isinstance(friend, str)\n",
      "\n",
      "This code defines a fixture called token that returns the same string every time it's called. Then it defines a test function called test_get_friend_list that takes the token fixture as an argument. Inside the test function, it creates a GraphAPI object using the token, gets the user's profile and friends, creates a list of friend names, and checks that the list is not empty and that each friend name is a string. If any of these checks fail, pytest will report an error. \n"
     ]
    }
   ],
   "source": [
    "codes=\"\"\" Given the below code, provide unit testing code with pytest\n",
    "\n",
    "import facebook\n",
    "\n",
    "token = 'your token'\n",
    "\n",
    "graph = facebook.GraphAPI(token)\n",
    "profile = graph.get_object(\"me\")\n",
    "friends = graph.get_connections(\"me\", \"friends\")\n",
    "friend_list = [friend['name'] for friend in friends['data']]\n",
    "print friend_list\"\"\"\n",
    "\n",
    "\n",
    "replicate_response = granite_via_replicate.invoke(codes)\n",
    "\n",
    "print(f\"Granite response from Replicate: {replicate_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

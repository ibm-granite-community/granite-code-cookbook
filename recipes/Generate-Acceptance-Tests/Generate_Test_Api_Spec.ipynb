{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e98b2a4-cf47-4523-bd07-827683728d31",
   "metadata": {},
   "source": [
    "<h2> Generate Acceptance Test Python code covering open api specification behaviour using ibm-granite-code hosted on Replicate</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd9f68",
   "metadata": {},
   "source": [
    "<h3>Notebook goals:</h3>\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "1. Connect to `ibm-granite/granite-8b-code-instruct-128k` hosted on Replicate, and use it to Generate code for Acceptance Test Python Code\n",
    "2. Connect to `ibm-granite/granite-20b-code-instruct-8k` hosted on Replicate, and use it to Generate code for Acceptance Test Python Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2578b0",
   "metadata": {},
   "source": [
    "<h3>Prerequisites: </h3>\n",
    "\n",
    "1. Create an account on Replicate.\n",
    "2. Copy the Replicate API Token to an environment file (.env file) and place it in the same directory as this notebook. Environment variable can be named as `REPLICATE_API_TOKEN`.\n",
    "3. Install `langchain` and `ibm-granite-community/utils` python packages using below pip command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install git+https://github.com/ibm-granite-community/utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45854-f221-466b-a0b4-78effeae9f41",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad0a1a",
   "metadata": {},
   "source": [
    "<h3>Acceptance tests: OpenAPI specification</h3>\n",
    "\n",
    "1. Designed for user, who inputs (chat UI) or selects (IDE plugin) an OpenAPI specification to request generation of acceptance tests for it.\n",
    "2. Creates a response from the system that returns the acceptance test Python code that covers the behavior of the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10934b-14de-4b36-a251-1178a3ada873",
   "metadata": {},
   "source": [
    "## Using a local model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352513c",
   "metadata": {},
   "source": [
    "<h3>Get the variables from .env file</h3>\n",
    "\n",
    "This guide will demonstrate a basic inference call using the replicate package.\n",
    "\n",
    "To establish an authenticated session, the code below imports necessary packages, and loads the environment variable `REPLICATE_API_TOKEN` from the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc017ba-fe00-43a4-9299-d4610946076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_granite_community.langchain_utils import find_langchain_model\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API token directly from environment variables\n",
    "replicate_api_token = os.getenv('REPLICATE_API_TOKEN')\n",
    "\n",
    "if replicate_api_token:\n",
    "    print('API token loaded successfully:', replicate_api_token)\n",
    "else:\n",
    "    print('Failed to load API token. Please check your .env file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c0dce-3630-4408-bd51-23db676874cf",
   "metadata": {},
   "source": [
    "## Using a remotely-hosted model\n",
    "\n",
    "The Granite Code models are available on [Replicate](https://replicate.com/).\n",
    "\n",
    "At the moment, they are only available to members of the Granite Code team.\n",
    "Request an invite to get access.\n",
    "\n",
    "This guide will demonstrate a basic inference call using the `replicate` package as well\n",
    "as via LangChain.\n",
    "In both cases, you will provide a [Replicate API Token](https://replicate.com/account/api-tokens).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465c776-857f-48ec-ad32-40f5d6577c3a",
   "metadata": {},
   "source": [
    "<h3>Deployment ID and Model ID Specifications</h3>\n",
    "\n",
    "Mention the Deployment ID as granite and Specify the Model ID to be used for building the use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eeb4c2e-ec15-4b73-8229-35dae503115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = \"ibm/granite-dev\"\n",
    "\n",
    "model_id = \"ibm/granite-8b-code-instruct:50da94a0b1b5d28e3161d1312077d856eb673b87e633438362e4820fed563444\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4497b8b-786f-4b40-b0c9-0c12ad180219",
   "metadata": {},
   "source": [
    "<h3>Prompt Definition</h3>\n",
    "\n",
    "We further need to specify the prompt as an input to the model with apt configuration by including within it the specification along with the correct requirements needed. \n",
    "\n",
    "For an instance, in this use case, we implement the prompt to contain an instruction for generating acceptance test in the form of python code to cover the behavior of application of open api onto testing orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f99de7-ff2e-4ae4-b1f2-1ac4453b4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please generate acceptance test Python code that covers the behavior of the open api specification as per the specification \\\\n\\\\nopenapi: 3.0.0\\\\ninfo:\\\\n  title: Test Generation System\\\\n  description: API for creating test scenarios for orders\\\\n  version: 1.0.0\\\\npaths:\\\\n  /orders/count:\\\\n    get:\\\\n      summary: Test the fetch query for the count of orders in the system\\\\n      responses:\\\\n        200:\\\\n          description: OK\\\\n          content:\\\\n            application/json:\\\\n              schema:\\\\n\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20e206-40b8-4f45-a7a3-6e22d1c76c90",
   "metadata": {},
   "source": [
    "### Replicate package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba85a7",
   "metadata": {},
   "source": [
    "Python package replicate needs to be installed for being imported in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdf174-6f25-432c-b2d6-6370f4eff98b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67dbe7",
   "metadata": {},
   "source": [
    "<h3>Import all the necessary libraries and packages</h3>\n",
    "\n",
    "Replicate package needs to be imported in order to be used for refering to the deployment for which the prompt is being directed to achieving the test/s generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65423430-1e61-4ed8-8396-3f96860463fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819e892",
   "metadata": {},
   "source": [
    "<h3>Fetching Acceptance Test as response to the prompt</h3>\n",
    "\n",
    "Next, using replicate, prediction is created with the prompt designed as per the configuration in the previous step. Furthermore, the exception handling is curated onto the response of the prompt to generate clean output for the user in terms of the test generated inclusing error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d4153-3900-473c-a46b-d5e326dfb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = replicate.deployments.get(deployment_id)\n",
    "print(\"prompt\", prompt)\n",
    "prediction = deployment.predictions.create(\n",
    "  input={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "prediction.wait()\n",
    "\n",
    "if (prediction.output[0].__contains__('mock')): \n",
    "  print('The provided input specification seems corrupted. Kindly check again and reattampt.')\n",
    "else:\n",
    "  print(prediction.output[0].split('```python')[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Use Remote and Local Granite Code Models with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction and Setup\n",
    "\n",
    "This notebook demonstrates using inference calls against a model hosted remotely on [Replicate](https://replicate.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "Granite Kitchen comes with a bundle of dependencies that are required for notebooks. See the list of packages in its [`setup.py`](https://github.com/ibm-granite-community/granite-kitchen/blob/main/setup.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/granite-kitchen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Using a Remote Model on Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Establish Replicate Account\n",
    "\n",
    "To use this remote option, create an account at [Replicate](https://replicate.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Add credit to your Replicate Account (optional)\n",
    "\n",
    "To remove a barrier to entry to try the Granite Code models on the Replicate platform,\n",
    "use [this link](https://replicate.com/invites/a8717bfe-2f3d-4a52-88ed-1356231cdf03) to add a\n",
    "small amount of credit to your Replicate account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Provide your API Token\n",
    "\n",
    "Obtain your `REPLICATE_API_TOKEN` at [replicate.com/account/api-tokens](https://replicate.com/account/api-tokens)\n",
    "\n",
    "There are three ways to provide this value to the cells below.  In order of precedence:\n",
    "\n",
    "1. As an environment variable\n",
    "2. As a Google colab secret\n",
    "3. Supplied by the user using `getpass()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Choose a Model\n",
    "\n",
    "Two Granite Code models are available in the [`ibm-granite`](https://replicate.com/ibm-granite) org at Replicate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm-granite/granite-8b-code-instruct-128k\"\n",
    "# model_id = \"ibm-granite/granite-20b-code-instruct-8k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Instantiate the model client\n",
    "\n",
    "Use the Langchain client to connect to the Granite Code LLM on Replicate.\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from [this LLM component recipe](https://github.com/ibm-granite-community/utils/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_community.llms import Replicate\n",
    "\n",
    "model = Replicate(\n",
    "    model=model_id,\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Perform Inference\n",
    "\n",
    "Define a prompt and invoke the granite model on Replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Show me a SQL query that fetches all columns for the first 50 rows\n",
    "    in a table named 'users'.\"\"\"\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "print(f\"Granite response from Replicate:\\n\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

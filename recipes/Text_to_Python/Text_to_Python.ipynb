{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Generating Python Code with Granite\n",
    "\n",
    "**NOTE:** This recipe demonstrates how to use Granite Models to generate Python code from text prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "**Install dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install \"git+https://github.com/ibm-granite-community/utils\" \\\n",
    "    langchain_community \\\n",
    "    transformers \\\n",
    "    replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**Select a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_community.llms import Replicate\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path=\"ibm-granite/granite-3.3-8b-instruct\"\n",
    "\n",
    "model = Replicate(\n",
    "    model=model_path,\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### One-shot Prompting with Granite\n",
    "\n",
    "In One-shot prompting, you provide the model with a question and no examples. The model will generate an answer based on its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from ibm_granite_community.langchain import TokenizerChatPromptTemplate\n",
    "\n",
    "prompt = TokenizerChatPromptTemplate.from_template(dedent(\"\"\"\\\n",
    "    Generate the Fibonacci sequence up to n terms.\n",
    "    Used in Georgia Tech's CS 1301 course demonstrations.\n",
    "    Args:\n",
    "        n: Number of terms to generate\n",
    "    Returns:\n",
    "        List containing the Fibonacci sequence\n",
    "    Raises:\n",
    "        ValueError: If n is negative\n",
    "\"\"\"),\n",
    "tokenizer=tokenizer).format()\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Try the code\n",
    "\n",
    "Copy and paste the generated code here to test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your code here!\n",
    "def fibonacci(n):\n",
    " if n < 0:\n",
    "    raise ValueError(\"n must be a non-negative integer\")\n",
    " elif n == 0:\n",
    "    return []\n",
    " elif n == 1:\n",
    "    return [0]\n",
    " else:\n",
    "    fib_seq = [0, 1]\n",
    "\n",
    " for i in range(2, n):\n",
    "    fib_seq.append(fib_seq[i-1] + fib_seq[i-2])\n",
    " return fib_seq\n",
    "\n",
    "# Test the function\n",
    "print(fibonacci(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Few-shot Prompting with Granite\n",
    "\n",
    "In few-shot prompting, you provide the model with a question and some examples to help it understand the pattern you want.\n",
    "\n",
    "**Provide a list of Q&A examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Write a function to calculate the GPA based on Georgia Tech's 4.0 scale\",\n",
    "        \"answer\": \"\"\"def calculate_gt_gpa(grades: list[str]) -> float:\n",
    "    \\\"\\\"\\\"\n",
    "    Calculate GPA based on Georgia Tech's 4.0 scale.\n",
    "\n",
    "    Args:\n",
    "        grades: List of letter grades (A, B, C, D, F)\n",
    "\n",
    "    Returns:\n",
    "        The calculated GPA on a 4.0 scale\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an invalid grade is provided\n",
    "    \\\"\\\"\\\"\n",
    "    grade_points = {'A': 4.0, 'B': 3.0, 'C': 2.0, 'D': 1.0, 'F': 0.0}\n",
    "\n",
    "    total_points = 0\n",
    "    for grade in grades:\n",
    "        if grade not in grade_points:\n",
    "            raise ValueError(f\"Invalid grade: {grade}\")\n",
    "        total_points += grade_points[grade]\n",
    "\n",
    "    return total_points / len(grades) if grades else 0.0\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Create a function to convert between Celsius and Fahrenheit for GT lab experiments\",\n",
    "        \"answer\": \"\"\"def convert_temperature(temp: float, to_unit: str) -> float:\n",
    "    \\\"\\\"\\\"\n",
    "    Convert temperature between Celsius and Fahrenheit for GT lab experiments.\n",
    "\n",
    "    Args:\n",
    "        temp: Temperature value to convert\n",
    "        to_unit: Target unit ('C' for Celsius, 'F' for Fahrenheit)\n",
    "\n",
    "    Returns:\n",
    "        Converted temperature value\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If to_unit is not 'C' or 'F'\n",
    "    \\\"\\\"\\\"\n",
    "    if to_unit not in ['C', 'F']:\n",
    "        raise ValueError(\"Unit must be 'C' or 'F'\")\n",
    "\n",
    "    if to_unit == 'C':\n",
    "        return (temp - 32) * 5/9\n",
    "    else:\n",
    "        return (temp * 9/5) + 32\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**Assemble the prompt template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{question}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "chat_template = TokenizerChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(chat_template.input_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "**View the completed prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a Python class for a Georgia Tech Credit Union account with methods for deposit, withdraw, check balance, and track transactions. Include a Buzz Card account type option.\"\n",
    "\n",
    "print(chat_template.format(question=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "**Run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | model\n",
    "response = chain.invoke({\"question\": prompt})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Adding a System Prompt\n",
    "\n",
    "A system prompt provides additional instructions and context for all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_prompt = SystemMessage(content=dedent(\"\"\"\\\n",
    "    You are a Python expert from Georgia Tech's College of Computing who writes clean,\n",
    "    efficient, and well-documented code. Follow PEP 8 style guidelines and Georgia Tech's\n",
    "    computational thinking principles.\n",
    "    Always include type hints and comprehensive docstrings. Only output Python code, no explanations.\n",
    "\"\"\"))\n",
    "\n",
    "chat_template_with_system_message = TokenizerChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_prompt,\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(chat_template_with_system_message.input_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**Run the model with system prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_sys = chat_template_with_system_message | model\n",
    "response = chain_sys.invoke({\"question\": prompt})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Copy and paste the generated code here to test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the generated response here and run it!\n",
    "class BankAccount:\n",
    "    def __init__(self, initial_balance: float = 0.0):\n",
    "        \"\"\"\n",
    "        BankAccount class for managing bank account transactions.\n",
    "\n",
    "        Args:\n",
    "            initial_balance: Initial balance for the account (default: 0.0)\n",
    "        \"\"\"\n",
    "        self.balance = initial_balance\n",
    "\n",
    "    def deposit(self, amount: float) -> None:\n",
    "        \"\"\"\n",
    "        Deposit amount into the bank account.\n",
    "\n",
    "        Args:\n",
    "            amount: Amount to deposit into the account\n",
    "        \"\"\"\n",
    "        self.balance += amount\n",
    "\n",
    "    def withdraw(self, amount: float) -> None:\n",
    "        \"\"\"\n",
    "        Withdraw amount from the bank account.\n",
    "\n",
    "        Args:\n",
    "            amount: Amount to withdraw from the account\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If withdrawal would result in a negative balance\n",
    "        \"\"\"\n",
    "        if self.balance - amount < 0:\n",
    "            raise ValueError(\"Insufficient funds\")\n",
    "        self.balance -= amount\n",
    "\n",
    "    def check_balance(self) -> float:\n",
    "        \"\"\"\n",
    "        Check the current balance of the bank account.\n",
    "\n",
    "        Returns:\n",
    "            Current balance of the account\n",
    "        \"\"\"\n",
    "        return self.balance\n",
    "\n",
    "# Test the BankAccount class\n",
    "if __name__ == \"__main__\":\n",
    "    account = BankAccount(100.0)\n",
    "    print(account)\n",
    "\n",
    "    account.deposit(50)\n",
    "    print(f\"Balance after deposit: ${account.check_balance():.2f}\")\n",
    "\n",
    "    account.withdraw(30)\n",
    "    print(f\"Balance after withdrawal: ${account.check_balance():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### For further study\n",
    "\n",
    "- Try different queries and test if the model generates correct Python code\n",
    "- Experiment with more complex programming tasks like data processing or algorithm implementation\n",
    "- Add more diverse examples to the `examples` list and see how it affects the outputs\n",
    "- Try generating different types of Python code (OOP vs. functional style)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

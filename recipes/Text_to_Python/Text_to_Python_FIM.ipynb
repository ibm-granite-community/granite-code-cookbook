{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Generating Python Code with Granite\n",
    "\n",
    "**NOTE:** This recipe demonstrates how to use Granite Models to generate Python code from text prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"git+https://github.com/ibm-granite-community/utils\" \\\n",
    "    langchain_community \\\n",
    "    transformers \\\n",
    "    replicate \\\n",
    "    pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Select and import the model from Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "from transformers import AutoTokenizer\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from ibm_granite_community.langchain import TokenizerChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from textwrap import dedent\n",
    "\n",
    "# Model configuration\n",
    "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "\n",
    "# Initialize Replicate model\n",
    "model = Replicate(\n",
    "    model=model_path,\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Configure the model to use tokenizer and chat template with a system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Create a system message for the chat prompt\n",
    "system_prompt = SystemMessage(content=dedent(\"\"\"\\\n",
    "    You are a Python code generation specialist. Your task is to perform Fill-in-the-Middle (FIM) code completion following these strict guidelines:\n",
    "\n",
    "    1. Generate ONLY executable Python code without any explanations or comments outside of docstrings\n",
    "    2. Follow PEP 8 style guidelines and best practices\n",
    "    3. Include appropriate type hints for all function parameters and return values\n",
    "    4. Write comprehensive docstrings following Google docstring format\n",
    "    5. Ensure the generated code fits seamlessly between the provided prefix and suffix\n",
    "    6. Maintain consistent indentation and naming conventions with surrounding code\n",
    "    7. Optimize for readability, efficiency, and maintainability\n",
    "    8. Do not include any natural language responses or explanations outside of code\n",
    "\n",
    "    Your response must consist solely of valid Python code that can be directly executed.\n",
    "\"\"\"))\n",
    "\n",
    "# Create a tokenizer chat prompt template with the system message\n",
    "chat_template_with_system_message = TokenizerChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "chain_sys = chat_template_with_system_message | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Configure the model to use the FIM (Fill-in-the-Middle) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fim_pipeline(prefix, suffix=\"\"):\n",
    "    # Format FIM input with special tokens\n",
    "    input_text = f'<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>'\n",
    "\n",
    "    # Generate using the Replicate model chain with system prompt\n",
    "    response = chain_sys.invoke({\"question\": input_text})\n",
    "\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### What is Fill-in-the-Middle (FIM)?\n",
    "Fill-in-the-Middle (FIM) is a technique where the model is provided with the beginning and end of a code snippet and is asked to complete the missing logic in the middle. This method is highly effective for:\n",
    "1) Completing core programming constructs like functions, methods, conditionals, and loops\n",
    "2) Implementing common algorithms (e.g., prime checks, factorials, string reversal)\n",
    "3) Demonstrating language-agnostic problem-solving across languages like Python, C/C++, Go, and Java\n",
    "4) Teaching introductory programming concepts by auto-completing starter code\n",
    "5) Assisting learners with template-based coding exercises\n",
    "6) Rapidly generating idiomatic solutions using best practices in each language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Example №1: Bug Fixing (missing loop logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "def sum_even_numbers(lst):\n",
    "    total = 0\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    return total\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "def sum_even_numbers(lst):\n",
    "    total = 0\n",
    "    for num in lst:\n",
    "        if num % 2 == 0:\n",
    "            total += num\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Example №2: Adding Missing Implementation (class method logic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def increment(self):\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    return self.count\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "        return self.count\n",
    "\n",
    "    def decrement(self):\n",
    "        self.count -= 1\n",
    "        return self.count\n",
    "\n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Example №3: Loop Completion for Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "def filter_positive(nums):\n",
    "    result = []\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "def filter_positive(nums):\n",
    "    result = []\n",
    "    for num in nums:\n",
    "        if num > 0:\n",
    "            result.append(num)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Example №4: Error Handling Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "def read_file(path):\n",
    "    try:\n",
    "        with open(path, 'r') as file:\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\"\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "def read_file(path):\n",
    "    try:\n",
    "        with open(path, 'r') as file:\n",
    "            content = file.read()\n",
    "            return content\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Example №5: Data Transformation with List Comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "def square_even(nums):\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "def square_even(nums):\n",
    "    result = [num ** 2 for num in nums if num % 2 == 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Example №6: Partial Code Completion in Data Analysis Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_clean(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "    return df\n",
    "\"\"\"\n",
    "\n",
    "print(fim_pipeline(prefix=prefix, suffix=suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this code into a Python environment to run it\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_clean(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.dropna(inplace=True)  # Remove missing values\n",
    "    df.reset_index(drop=True, inplace=True)  # Reset index after dropping rows\n",
    "    df['column_name'] = df['column_name'].astype('int')\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428dbbfa206f5417",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Using CLDK to generate JUnit tests\n",
    "\n",
    "In this tutorial, we will use [CLDK](https://github.com/IBM/codellm-devkit/tree/main) to implement a simple unit test generator for Java. You'll explore some of the benefits of using CLDK to perform quick and easy program analysis and build an LLM-based test generator. By the end of this tutorial, you will have implemented such a tool and generated a [JUnit](https://junit.org/) test case for a Java application.\n",
    "\n",
    "Specifically, you will learn how to perform the following tasks on the application under test to create LLM prompts for test generation:\n",
    "\n",
    "1. Create a new instance of the CLDK class.\n",
    "2. Create an analysis object for the Java application under test.\n",
    "3. Iterate over all files in the application.\n",
    "4. Iterate over all classes in a file.\n",
    "5. Iterate over all methods in a class.\n",
    "6. Get the code body of a method.\n",
    "7. Get the constructors of a class.\n",
    "<!-- 7. Initialize treesitter utils for the class file content.\n",
    "8. Sanitize the class for analysis. -->\n",
    "\n",
    "We will write several helper methods to 1) format the LLM instruction for generating test cases for a given focal method (i.e., method under test) and 2) prompt the LLM via Ollama. We will then use CLDK to go through an application and generate unit test cases for the target method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619a9379b9dd006",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Prequisites\n",
    "\n",
    "See the [Code Sumarization](./code_summarization.ipynb) recipe, which describes the prerequisites and set up that are required for this notebook, as well. These prerequisites include Python 3.11 or later, Java 11 or later, Maven 3.9 or later, [Ollama 0.3.4](https://ollama.com/) or later, [Granite code models](https://ollama.com/library/granite-code), a sample Java application (the [Apache Commons CLI](https://github.com/apache/commons-cli), and the CLDK tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b514f-4dbf-44a1-bdd6-327289cd4647",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Build a JUnit test generator using CLDK and Granite Code Model\n",
    "\n",
    "Let's build a JUnit test generator using CLDK and the Granite Code Instruct Model.\n",
    "\n",
    "Generating unit tests for code is an important task and developers often have to put in significant effort in writing good test cases. There are various tools available for automated test generation, such as EvoSuite, which uses evolutionary algorithms to generate unit test cases for Java. However, the generated test cases are not natural and often developers do not prefer to add them to their test suites. LLMs, having been trained with developer-written code, have a better affinity towards generating more natural code, code that is more readable, comprehensible, and maintainable. In this excercise, we will show how we can leverage LLMs to generate test cases with the help of CLDK.\n",
    "\n",
    "For simplicity, we will cover certain aspects of test generation and provide some context information to the LLM to help it create usable test cases. In this exercise, we will generate a unit test for a non-private method from a Java class and provide the focal method body and the signature of all the constructors of the class so that LLM can understand how to create an object of the focal class during the setup phase of the tests.\n",
    "<!-- Also, we will ask LLMs to generate ```N``` number of test cases, where ```N``` is the cyclomatic complexity of the focal method. The intuition is that one test may not be sufficient for covering fairly complex methods, and a cyclomatic complexity score can provide some guidance towards that.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a9801",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/IBM/codellm-devkit.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f3752-4c4f-4d4e-a738-86dd4acfcdc6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Step 1: Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2498ae092fcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "from cldk import CLDK\n",
    "from cldk.analysis import AnalysisLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb24b29826d730",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Step 2: Define a function for creating the LLM prompt\n",
    "\n",
    "This function instructs the LLM to generate unit tests cases and includes signatures of relevant constructors and the body of the focal method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9bbaa917df24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def format_inst(focal_method_body, focal_method, focal_class, constructor_signatures, language):\n",
    "    \"\"\"\n",
    "    Format the LLM instruction for the given focal method and class.\n",
    "    \"\"\"\n",
    "    inst = f\"Question: Can you generate junit tests with @Test annotation for the method `{focal_method}` in the class `{focal_class}` below. Only generate the test and no description.\\n\"\n",
    "    inst += 'Use the constructor signatures to form the object if the method is not static. Generate the code under ``` code block.'\n",
    "    inst += \"\\n\"\n",
    "    inst += f\"```{language}\\n\"\n",
    "    inst += f\"public class {focal_class} \" + \"{\\n\"\n",
    "    inst += f\"{constructor_signatures}\\n\"\n",
    "    inst += f\"{focal_method_body} \\n\"\n",
    "    inst += \"}\"\n",
    "    inst += \"```\\n\"\n",
    "    inst += \"Answer:\\n\"\n",
    "    return inst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ceb150f5efa92",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Step 3: Define a function to call the LLM\n",
    "\n",
    "As before in the [Code Sumarization](./code_summarization.ipynb) recipe, we use Ollama with Granite Code 3b Instruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52634feae7374599",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def prompt_ollama(message: str, model_id: str = \"granite-code:3b\") -> str:\n",
    "    \"\"\"Prompt local model on Ollama\"\"\"\n",
    "    response_object = ollama.generate(model=model_id, prompt=message, options={\"temperature\":0.2})\n",
    "    return response_object[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c3325116b87d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Step 4: Collect the relevant information for the focal method and prompt the LLM\n",
    "\n",
    "To do this, we go through all the classes in the application, and for each class, we collect the signatures of its constructors. If a class has no constructors, we add the signature of the default constructor. Then, we go through each non-private method of the class and formulate the prompt using the constructor and the method information. Finally, we use the prompt to call the LLM to generate test cases and get the LLM response. If the analysis has been run already, for example in the [Code Sumarization](./code_summarization.ipynb) recipe, CLDK will use the existing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9558e4de65a52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of CLDK for Java analysis\n",
    "cldk = CLDK(language=\"java\")\n",
    "\n",
    "# Create an analysis object for the Java application. Provide the application path.\n",
    "analysis = cldk.analysis(project_path=\"temp/commons-cli-rel-commons-cli-1.7.0\", analysis_level=AnalysisLevel.symbol_table, analysis_json_path='analysis')\n",
    "\n",
    "# For simplicity, we run the test generation on a single focal class and method (this filter can be removed to run this code over the entire application)\n",
    "focal_class = \"org.apache.commons.cli.GnuParser\"\n",
    "focal_method = \"flatten(Options, String[], boolean)\"\n",
    "\n",
    "# Go through all the classes in the application\n",
    "for class_name in analysis.get_classes():\n",
    "\n",
    "    if class_name == focal_class:\n",
    "        print(f\"Class: {class_name}\")\n",
    "        class_details  = analysis.get_class(qualified_class_name=class_name)\n",
    "        focal_class_name = class_name.split(\".\")[-1]\n",
    "\n",
    "        # Generate test cases for non-interface and non-abstract classes\n",
    "        if not class_details.is_interface and \"abstract\" not in class_details.modifiers:\n",
    "\n",
    "            # Get all constructor signatures\n",
    "            constructor_signatures = \"\"\n",
    "\n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "                method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "\n",
    "                if method_details.is_constructor:\n",
    "                    constructor_signatures += method_details.signature + '\\n'\n",
    "\n",
    "            # If no constructor present, then add the signature of the default constructor\n",
    "            if constructor_signatures == \"\":\n",
    "                constructor_signatures = f\"public {focal_class_name}() \" + \"{}\"\n",
    "\n",
    "            # Go through all the methods in the class\n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "                if method == focal_method:\n",
    "                    # Get the method details\n",
    "                    method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "\n",
    "                    # Generate test cases for non-private methods\n",
    "                    if \"private\" not in method_details.modifiers and not method_details.is_constructor:\n",
    "\n",
    "                        # Gather all the information needed for the prompt, which are focal method body, focal method name, focal class name, and constructor signature\n",
    "                        prompt = format_inst(\n",
    "                            focal_method_body=method_details.declaration+method_details.code,\n",
    "                            focal_method=method.split(\"(\")[0],\n",
    "                            focal_class=focal_class_name,\n",
    "                            constructor_signatures=constructor_signatures,\n",
    "                            language=\"java\"\n",
    "                        )\n",
    "\n",
    "                        # Print the instruction\n",
    "                        print(f\"Instruction:\\n{prompt}\\n\")\n",
    "                        print(f\"Generating test case and it will take few minutes (or even seconds) based on where the model has been hosted...\\n\")\n",
    "\n",
    "                        # Prompt the local model on Ollama\n",
    "                        llm_output = prompt_ollama(message=prompt)\n",
    "\n",
    "                        # Print the LLM output\n",
    "                        print(f\"LLM Output:\\n{llm_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339366cc-a8d4-4487-bfeb-56813af06602",
   "metadata": {},
   "source": [
    "Note that a file [./analysis/analysis.json](./analysis/analysis.json) was created or reused from a previous run, such as the [Code Sumarization](./code_summarization.ipynb) recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407441b",
   "metadata": {},
   "source": [
    "After the LLM's response is received, you should see the generated test case for the `flatten` method printed out. Here is an example of what you might see:\n",
    "\n",
    "```java\n",
    "import static org.junit.jupiter.api.Assertions.assertEquals;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "import org.apache.commons.cli.Options;\n",
    "import org.junit.jupiter.api.Test;\n",
    "\n",
    "class GnuParserTest {\n",
    "\n",
    "    @Test\n",
    "    void testFlatten() {\n",
    "        final Options options = new Options();\n",
    "        final String[] arguments = {};\n",
    "        final boolean stopAtNonOption = false;\n",
    "\n",
    "        final String[] expected = {};\n",
    "        final String[] actual = GnuParser.flatten(options, arguments, stopAtNonOption);\n",
    "\n",
    "        assertEquals(expected, actual);\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428dbbfa206f5417",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Using CLDK to generate JUnit tests\n",
    "\n",
    "In this tutorial, we will use [CLDK](https://github.com/IBM/codellm-devkit/tree/main) to implement a simple unit test generator for Java. You'll explore some of the benefits of using CLDK to perform quick and easy program analysis and build an LLM-based test generator. By the end of this tutorial, you will have implemented such a tool and generated a JUnit test case for a Java application.\n",
    "\n",
    "Specifically, you will learn how to perform the following tasks on the application under test to create LLM prompts for test generation:\n",
    "\n",
    "1. Create a new instance of the CLDK class.\n",
    "2. Create an analysis object for the Java application under test.\n",
    "3. Iterate over all files in the application.\n",
    "4. Iterate over all classes in a file.\n",
    "5. Iterate over all methods in a class.\n",
    "6. Get the code body of a method.\n",
    "7. Get the constructors of a class.\n",
    "<!-- 7. Initialize treesitter utils for the class file content.\n",
    "8. Sanitize the class for analysis. -->\n",
    "\n",
    "We will write a couple of helper methods to (1) format the LLM instruction for generating test cases for a given focal method (i.e., method under test) and (2) prompt the LLM via Ollama. We will then use CLDK to go through an application and generate unit test cases for the target method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619a9379b9dd006",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Prequisites\n",
    "\n",
    "See the [Code Sumarization](./code_summarization.ipynb) recipe, which describes the prerequisites and set up that are required for this notebook, as well. These prerequisites include Python 3.11 or later, Java 11 or later, Maven 3.9 or later, [Ollama 0.3.4](https://ollama.com/) or later, [Granite code models](https://ollama.com/library/granite-code), a sample Java application (the [Apache Commons CLI](https://github.com/apache/commons-cli), and the CKDK tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e69eb0bccedfc9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Build a JUnit test generator using CLDK and Granite Code Model\n",
    "\n",
    "Let's build a JUnit test generator using CLDK and the Granite Code Instruct Model.\n",
    "\n",
    "Generating unit tests for code is an important task and developers often have to put in significant effort in writing good test cases. There are various tools available for automated test generation, such as EvoSuite, which uses evolutionary algorithms to generate unit test cases for Java. However, the generated test cases are not natural and often developers do not prefer to add them to their test suites. LLMs, having been trained with developer-written code, have a better affinity towards generating more natural code, code that is more readable, comprehensible, and maintainable. In this excercise, we will show how we can leverage LLMs to generate test cases with the help of CLDK. \n",
    "\n",
    "For simplicity, we will cover certain aspects of test generation and provide some context information to the LLM to help it create usable test cases. In this exercise, we will generate a unit test for a non-private method from a Java class and provide the focal method body and the signature of all the constructors of the class so that LLM can understand how to create an object of the focal class during the setup phase of the tests.\n",
    "<!-- Also, we will ask LLMs to generate ```N``` number of test cases, where ```N``` is the cyclomatic complexity of the focal method. The intuition is that one test may not be sufficient for covering fairly complex methods, and a cyclomatic complexity score can provide some guidance towards that.  -->\n",
    "\n",
    "Step 1: Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2498ae092fcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "from cldk import CLDK\n",
    "from cldk.analysis import AnalysisLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb24b29826d730",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Step 2: Define a function for creating the LLM prompt, which instructs the LLM to generate unit tests cases and includes signatures of relevant constructors and the body of the focal method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9bbaa917df24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def format_inst(focal_method_body, focal_method, focal_class, constructor_signatures, language):\n",
    "    \"\"\"\n",
    "    Format the LLM instruction for the given focal method and class.\n",
    "    \"\"\"\n",
    "    inst = f\"Question: Can you generate junit tests with @Test annotation for the method `{focal_method}` in the class `{focal_class}` below. Only generate the test and no description.\\n\"\n",
    "    inst += 'Use the constructor signatures to form the object if the method is not static. Generate the code under ``` code block.'\n",
    "    inst += \"\\n\"\n",
    "    inst += f\"```{language}\\n\"\n",
    "    inst += f\"public class {focal_class} \" + \"{\\n\"\n",
    "    inst += f\"{constructor_signatures}\\n\"\n",
    "    inst += f\"{focal_method_body} \\n\" \n",
    "    inst += \"}\"\n",
    "    inst += \"```\\n\"\n",
    "    inst += \"Answer:\\n\"\n",
    "    return inst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ceb150f5efa92",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Step 3: Define a function to call the LLM (in this case, Granite code 8b-instruct) using Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52634feae7374599",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def prompt_ollama(message: str, model_id: str = \"granite-code:8b-instruct\") -> str:\n",
    "    \"\"\"Prompt local model on Ollama\"\"\"\n",
    "    response_object = ollama.generate(model=model_id, prompt=message, options={\"temperature\":0.2})\n",
    "    return response_object[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c3325116b87d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Step 4: Collect the relevant information for the focal method and prompt the LLM. To do this, we go through all the classes in the application, and for each class, we collect the signatures of its constructors. If a class has no constructors, we add the signature of the default constructor. Then, we go through each non-private method of the class and formulate the prompt using the constructor and the method information. Finally, we use the prompt to call LLM to generate test cases and get the LLM response. If analysis has been run already, CLDK will use the existing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9558e4de65a52",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an instance of CLDK for Java analysis\n",
    "cldk = CLDK(language=\"java\")\n",
    "\n",
    "# Create an analysis object for the Java application. Provide the application path.\n",
    "analysis = cldk.analysis(project_path=\"temp/commons-cli-rel-commons-cli-1.7.0\", analysis_level=AnalysisLevel.symbol_table, analysis_json_path='analysis')\n",
    "\n",
    "# For simplicity, we run the test generation on a single focal class and method (this filter can be removed to run this code over the entire application)\n",
    "focal_class = \"org.apache.commons.cli.GnuParser\"\n",
    "focal_method = \"flatten(Options, String[], boolean)\"\n",
    "\n",
    "# Go through all the classes in the application\n",
    "for class_name in analysis.get_classes():\n",
    "\n",
    "    if class_name == focal_class:\n",
    "        print(f\"Class: {class_name}\")\n",
    "        class_details  = analysis.get_class(qualified_class_name=class_name)\n",
    "        focal_class_name = class_name.split(\".\")[-1]\n",
    "\n",
    "        # Generate test cases for non-interface and non-abstract classes\n",
    "        if not class_details.is_interface and \"abstract\" not in class_details.modifiers:\n",
    "            \n",
    "            # Get all constructor signatures\n",
    "            constructor_signatures = \"\"\n",
    "            \n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):\n",
    "                method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "                \n",
    "                if method_details.is_constructor:\n",
    "                    constructor_signatures += method_details.signature + '\\n'\n",
    "            \n",
    "            # If no constructor present, then add the signature of the default constructor\n",
    "            if constructor_signatures == \"\":\n",
    "                constructor_signatures = f\"public {focal_class_name}() \" + \"{}\"\n",
    "            \n",
    "            # Go through all the methods in the class\n",
    "            for method in analysis.get_methods_in_class(qualified_class_name=class_name):               \n",
    "                if method == focal_method:\n",
    "                    # Get the method details\n",
    "                    method_details = analysis.get_method(qualified_class_name=class_name, qualified_method_name=method)\n",
    "                    \n",
    "                    # Generate test cases for non-private methods\n",
    "                    if \"private\" not in method_details.modifiers and not method_details.is_constructor:\n",
    "                        \n",
    "                        # Gather all the information needed for the prompt, which are focal method body, focal method name, focal class name, and constructor signature\n",
    "                        prompt = format_inst(\n",
    "                            focal_method_body=method_details.declaration+method_details.code,\n",
    "                            focal_method=method.split(\"(\")[0],\n",
    "                            focal_class=focal_class_name,\n",
    "                            constructor_signatures=constructor_signatures,\n",
    "                            language=\"java\"\n",
    "                        )\n",
    "                        \n",
    "                        # Print the instruction\n",
    "                        print(f\"Instruction:\\n{prompt}\\n\")\n",
    "                        print(f\"Generating test case and it will take few minutes (or even seconds) based on where the model has been hosted...\\n\")\n",
    "                        \n",
    "                        # Prompt the local model on Ollama\n",
    "                        llm_output = prompt_ollama(message=prompt)\n",
    "                        \n",
    "                        # Print the LLM output\n",
    "                        print(f\"LLM Output:\\n{llm_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339366cc-a8d4-4487-bfeb-56813af06602",
   "metadata": {},
   "source": [
    "Note that a file [analysis.json](./analysis/analysis.json) was used from existing ```analysis``` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407441b",
   "metadata": {},
   "source": [
    "After the LLM's response is received, you should see the generated test case for the `flatten` method printed out (similar to the following).\n",
    "\n",
    "**LLM Output:**\n",
    "```java\n",
    "import static org.junit.jupiter.api.Assertions.assertEquals;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "import org.apache.commons.cli.Options;\n",
    "import org.junit.jupiter.api.Test;\n",
    "\n",
    "class GnuParserTest {\n",
    "\n",
    "    @Test\n",
    "    void testFlatten() {\n",
    "        final Options options = new Options();\n",
    "        final String[] arguments = {};\n",
    "        final boolean stopAtNonOption = false;\n",
    "\n",
    "        final String[] expected = {};\n",
    "        final String[] actual = GnuParser.flatten(options, arguments, stopAtNonOption);\n",
    "\n",
    "        assertEquals(expected, actual);\n",
    "    }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
